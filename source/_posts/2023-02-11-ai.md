---
title: Artificial Intelligence 
date: 2023-02-11 10:55:40
tags: think
categories: note
---

![](/images/post/20230211/ai.jpeg)

最近ChatGPT火出圈了哈，就连主流媒体都报道此事。
随着微软Bing对其集成，Google Bard的出师乏力，还有国内厂商的蠢蠢欲动，各大资本蜂拥而至进入此赛道，与人工智能相关事物都开始吸引了大家的目光。

据我所知，其实ChatGPT 2022年11月底就发布了，而我是2022年12月底才知道的，而2023年1月就成为了热门话题。

<!-- more -->

在成为公众热门话题之前，就会偶尔看到某些视频或文章提及人工智能ChatGPT将代替XXXX，满满的散播焦虑，博人眼球。
现在ChatGPT火出了IT圈，已然成为全民话题时这样的言论更是滔滔不绝了。（当然也有积极言论，但不如夸大的风险更吸引人）

你会怎么想？
由于ChatGPT对部分地区的使用限制，所以我并没有使用ChatGPT很多，但是也通过一些方式对其有了些许了解。
简单说ChatGPT 通过人类提供的广量数据进行训练学习，形成了一个对话模型。
起初这个过程会有人类给其反馈，哪些答案是合理的、可以采纳的或者不可取的。随后它可以基于这些已知基准进行海量学习锻炼自己的逻辑
然后再通过实战（投入使用），收集实际用户反馈，不断优化自身的判断、分析、反馈等模型。

可以看出其本质是基于人类提供的基准，做了海量的信息处理，而获得快速反馈能力（从中找到你想要的），但实际底层，他还是从人类哪里获得"知识"（你不说它是不会知道的）
然后向你复述出相对来说最有可能是正确的（符合大众想法，合理的 —— 概率问题）答案。
他在模仿人说话，是因为它处理了基于自然语言的数据，然后将数据合理编排（概率方式）提供给你
可以说它是人云亦云，只是它参考很多人的话，然后分析总结，找出最可能的（概率）话告诉你

明白了原理，此时你还会认为他会代替人类吗？我的答案是，不会，现在担心这个还有点早，
如果有一天它真的可以理解这些话中的概念，并有自主创新能力和自主思想时（创造一些新概念），我才会担心。
目前人工智能还是在浅显的模拟人类行为，通过大数据和科学家都很难说清楚底层运行原理的训练模型（概率模型）给你展示出近乎人类的反馈的"假象"
简单说，认知能力，我不认为现在AI具备此能力，只是假装，好像有而已。
目前AI还是一个高级的信息搬运工，不仅搬运还会组合，不会原创数据（其实人类大部分时候也是搬运信息啦，提出思想理念人还是少数，我们交流大多时候也是在搬运）

会不会代替一些底层工作呢？应该会，但我感觉还需要一段时间的验证。
其实有了这样的工具应该是更多的帮助人类更好的获取信息，加快自身对信息或事物的处理能力，从繁杂的信息海洋中跳脱出来。
底层岗位被代替，不如说是让人类从低效工作方式中抽身出来，例如客服，或者场景相对固定，重复性较强的工作。
而我们需要做的是，使用这样的工具提升，辅助自己，去做更有价值的工作。

Elon Mask 所担心的人工智能，绝对不是在ChatGPT这个层面，当然事物的发展肯定是从类ChatGPT 这样的阶段开始的。
时代在快速发展变化，我们要做的应该是拥抱它，接受改变的同时再不断的调整。
新事物的出现一定会带来一些变革，而人类的思想才是最重要的关键
从我们自身角度出发，没有人类的"文明"，没有任何意义。

## 我的担心

话说回来，为什么MS OpenAI会限制某些地区对ChatGPT使用呢？这个才是近期大家应该关心的吧
他们可能想通过先进工具来形成竞争优势，这才是更容易引发近期人类文明发展危机的根源
有没有想过这个场景，如果AI是人类训练出来的，正确答案的标准是某些人定的，那么每个团队训练出来的模型是否具有一定的判定标准倾向性。
目前来看，个个AI模型都刻意回避了敏感话题，但并不意味着其底层判断逻辑基准偏差未被设定。
今后可以通过更为隐秘的方式将一些"潜意识"思想传递给你，影响你的判断。（当然了，何为你的判断依据，就是你的认知）
所以如果你用这样的AI越多，相应的认知就会更符合AI想传递的标准，而这个标准不是AI制定的。

在我看来这个才是近期威胁，而又很少有人可以察觉。如果真的有一天AI有了自主意识，那么也许它可以更好的从道德和人类文明层面来判断个个事物，传达"正确"思想
但那时的危机就是，AI是否还会真的帮助人类，人类在AI看来还是否还值得帮助。

## 结束语
目前的理解，目前判断，胡说八道一下。
也许不久的将来再看，啪啪打脸，哈哈～～～

## 后续
对此话题的深入想象，让我有了更多想法，再多说两句。以下内容纯属无稽想象，也许可以当作科幻小说的主旨来看，未来应该变化很快，我大概率应该猜不对，但不妨碍我来锻炼以下想象力，看看我是否可以表述清楚我的想法

继续上面的思路，结合当今的发展。目前的AI在模拟人类的表达方式，我将其判定为信息组合和搬运，缺乏理解。而理解又是什么？
在我看来理解是基于我们自身感受对事物做出的主观判断，而这里的"自身感受"可能是目前AI所缺少的。AI通过大量数据可以模拟出人类情感化的反应，但那只是模仿
人类的自身感受来自很多方面，举例来说悲伤可能真的让你心脏剧痛，心律失常，痛哭不止，而这一切都会影响你的感受乃至判断。（AI的某些强大之处也是源于对情感处理的剔除，但我感觉需要合理优化）
而AI目前不会对此做出理解，当然今后的情感模型可以将这些感情信息量化为参数，让AI形成一个具有人类情感的反馈模型，应该不难想象。
但这时我要问，何为真实感受何为模拟呢？AI在不断完善的过程，其实是人类在不断模糊和打破判断边界的时候。反向我们在探索整个事物的根源，而根源也好像在我们探索时塌陷。

假设通过无限接近的模拟，"上帝"创造的人和人创造的AI最终的区别到底是什么呢？目前我先姑且将其本质区别归咎于"灵"（ghost in the shell）

人类AI的不断发展，人类科技水平不断提升，假设人类人口不断减少。这里为什么我用假设，因为这个关键参数我不确定后续发展情况：
* 按照当今发达国家发展趋势来看，还有目前对未来人口发展趋势的判断，人类总人口会在不远的将来迎来峰值，然后下滑，很多发达国家已经开始负增长
* 随着科技的发展，按理说人类的生活水平应该会不断提高，人类不再需要通过人海战术战术来对抗天灾人祸给个体带来的不确定性，例如：如果养老不是问题，有多少人会不要孩子
* 随着人工智能的发展，大量底层劳动力解放（不再需要），人口红利是否会被科技红利所代替

当然也有反向可能，但无论怎样，目前来看近期未来人类人口下滑的可能性还是更大一下，那么好了，我们是否可以假设，今后的社会结构是：
人类精英领袖层 <-> 高级科研人员 <-> 核心AI <-> 普通人 <-> 单点AI

不要规避人类阶级问题，至少我不认为在人类（肉体）消失前，阶级会消失。所以人类精英领袖层会存在，他们依旧是人类规则的制定者。
依赖于未来科技的发展，他们应该会可以活的很久，如很多科幻小说提及的那样，基因工程甚至可以帮助他们获得"永生"

高级科研人员，他们帮助精英领袖层来开发实现（管理）AI，目前看，人类终究不会完全信任AI，所以需要有高级人才来负责管理AI，他们也将完全凌驾于AI至上。
当然还有其它前沿科技的研究工作需要他们

核心AI，他们将会有无比强大的智慧，从生活常识到金融贸易，法律判定，核心AI应该都可以做出准确的分析和解答。此时普通人类可以借助核心AI的强大能力，快速掌握知识，处理事物等
普通人过着"普通幸福的"生活，那些需要体力的劳动可以交给单点AI专属设备完成，可以想象从农业到工业制造，几乎不需要人类体力参与。
普通人可以接受核心AI的指导并利用这些单点AI设备去完成一些具体工作，可能主要是维护单点AI设备
当然也包括人类文化延续，自娱自乐的内容

此时普通人类，可能已经不在经济活动的主体，也不是科技发展的核心动力，更多的是人类文明的延续基础保障
现在人口是一个国家经济活动的基础之一，其原因是与人口息息相关的国民生产总之以及相关资源消耗带来的贸易活动等。
如果以后一个人可以完成现在100个人的产出，那么人口减少了，生产总值不会减少，而一人可以消耗的资源变多。到时当今的经济学模型可能将被极大的挑战和颠覆。
简单说现在人类还在使用人海战术来实现，从量变到质变的过程。如果以后由于AI的介入，不需要了，普通人类会怎样？
我不会认为全人类都会变成科研工作者，肯定还是有一些"喜欢"做简单事的普通人

很多科幻电影都假设过这样的时代背景，贫富差距极大化的设想也是屡见不鲜，难道不能共同幸福吗？核心前提是什么？无限能源？核聚变的使用？
如果AI所需要的能源可以来自无限的核聚变乃至戴森球等形式。全人类真的可以共同幸福吗？ 感觉还是差了什么？
脑机接口，人类与核心AI通讯，然后实现心灵互通。（通过AI可以实现人类文明的统一，清楚杂念，这样会不会也同时抑制了人类思想的多样性？这里感觉会涉及到很多人权、伦理问题）
在脱离人类肉体之前，很多人性，人权，伦理，道德问题都无法规避和轻易解决。如果可以做到，那么这时就差精英阶层的统一了。
哈哈，这时他们之间是否可以达成共识，消除猜忌，将成为人类发展的关键了。

可能性很多，很多，也许很快我们就能看到一些重大改变，我期待着奇点的出现。

想的脑袋快宕机了，其实还有一个可能性，如果科技和能源可以得到极大发展，我们大脑开发水平是否可以提升，如果人类可以使用自身30%的大脑，那又会怎样？
我总有一种感觉，我们永远猜不到事物发展的趋势和重大转折，可能性和未知的事物太多了。
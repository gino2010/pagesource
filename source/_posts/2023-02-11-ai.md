---
title: Artificial Intelligence 
date: 2023-02-11 10:55:40
tags: think
categories: note
---

![](/images/post/20230211/ai.jpeg)

最近ChatGPT火出圈了哈，就连主流媒体都报道此事。
随着微软Bing对其集成，Google Bard的出师乏力，还有国内厂商的蠢蠢欲动，各大资本蜂拥而至进入此赛道，与人工智能相关事物都开始吸引了大家的目光。

据我所知，其实ChatGPT 2022年10月就发布了，而我是2022年12月才知道的，而2023年1月就成为了热门话题。

<!-- more -->

在成为公众热门话题之前，就会偶尔看到某些视频或文章提及人工智能ChatGPT将代替XXXX，满满的散播焦虑，博人眼球。
现在ChatGPT火出了IT圈，已然成为全民话题时这样的言论更是滔滔不绝了。（当然也有积极言论，但不如夸大的风险更吸引人）

你会怎么想？
由于ChatGPT对部分地区的使用限制，所以我并没有使用ChatGPT很多，但是也通过一些方式对其有了些许了解。
简单说ChatGPT 通过人类提供的广量数据进行训练学习，形成了一个对话模型。
起初这个过程会有人类给其反馈，哪些答案是合理的、可以采纳的或者不可取的。随后它可以基于这些已知基准进行海量学习锻炼自己的逻辑
然后再通过实战（投入使用），收集实际用户反馈，不断优化自身的判断、分析、反馈等模型。

可以看出其本质是基于人类提供的基准，做了海量的信息处理，而获得快速反馈能力（从中找到你想要的），但实际底层，他还是从人类哪里获得"知识"（你不说它是不会知道的）
然后向你复述出相对来说最有可能是正确的（符合大众想法，合理的 —— 概率问题）答案。
他在模仿人说话，是因为它处理了基于自然语言的数据，然后将数据合理编排（概率方式）提供给你
可以说它是人云亦云，只是它参考很多人的话，然后分析总结，找出最可能的（概率）话告诉你

明白了原理，此时你还会认为他会代替人类吗？我的答案是，不会，现在担心这个还有点早，
如果有一天它真的可以理解这些话中的概念，并有自主创新能力和自主思想时（创造一些新概念），我才会担心。
目前人工智能还是在浅显的模拟人类行为，通过大数据和科学家都很难说清楚底层运行原理的训练模型（概率模型）给你展示出近乎人类的反馈的"假象"
简单说，认知能力，我不认为现在AI具备此能力，只是假装，好像有而已。
目前AI还是一个高级的信息搬运工，不会原创数据（其实人类大部分时候也是搬运信息啦，提出思想理念人还是少数，我们交流也是在搬运）

会不会代替一些底层工作呢？应该会，但我感觉还需要一段时间的验证。
其实有了这样的工具应该是更多的帮助人类更好的获取信息，加快自身对信息或事物的处理能力，从繁杂的信息海洋中跳脱出来。
底层岗位被代替，不如说是让人类从低效工作方式中抽身出来，例如客服，或者场景相对固定，重复性较强的工作。
而我们需要做的是，使用这样的工具提升，辅助自己，去做更有价值的工作。

Elon Mask 所担心的人工智能，绝对不是在ChatGPT这个层面，当然事物的发展肯定是从类ChatGPT 这样的阶段开始的。
时代在快速发展变化，我们要做的应该是拥抱它，接受改变的同时再不断的调整。
新事物的出现一定会带来一些变革，而人类的思想才是最重要的关键
从我们自身角度出发，没有人类的"文明"，没有任何意义。

## 我的担心

话说回来，为什么MS OpenAI会限制某些地区对ChatGPT使用呢？这个才是近期大家应该关心的吧
他们可能想通过先进工具来形成竞争优势，这才是更容易引发近期人类文明发展危机的根源
有没有想过这个场景，如果AI是人类训练出来的，正确答案的标准是某些人定的，那么每个团队训练出来的模型是否具有一定的判定标准倾向性。
目前来看，个个AI模型都刻意回避了敏感话题，但并不意味着其底层判断逻辑基准偏差未被设定。
今后可以通过更为隐秘的方式将一些"潜意识"思想传递给你，影响你的判断。（当然了，何为你的判断依据，就是你的认知）
所以如果你用这样的AI越多，相应的认知就会更符合AI想传递的标准，而这个标准不是AI制定的。

在我看来这个才是近期威胁，而又很少有人可以察觉。如果真的有一天AI有了自主意识，那么也许它可以更好的从道德和人类文明层面来判断个个事物，传达"正确"思想
但那时的危机就是，AI是否还会真的帮助人类，人类在AI看来还是否还值得帮助。

## 结束语
目前的理解，目前判断，胡说八道一下。
也许不久的将来再看，啪啪打脸，哈哈～～～